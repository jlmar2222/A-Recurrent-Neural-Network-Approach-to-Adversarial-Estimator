# Adapting Adversarial Estimator for Time Series Data: A Recurrent Neural Network Approach

## Overview

This repository contains my Quantitative Economics Master's Thesis. It presents a novel approach to adapt the **Adversarial Estimator** for time series data. The Adversarial Estimator, originally developed by Kaji, Manresa, and Pouliot, integrates the powerful concept of Generative Adversarial Networks (GANs) into the parameter estimation framework. This project specifically addresses the challenge of handling the inherent serial correlation in time series, a limitation acknowledged by the original creators.

Our core contribution lies in designing and implementing a **Recurrent Neural Network (RNN) with a Long Short-Term Memory (LSTM) structure** as the Discriminator within this adversarial estimation setup. Furthermore, we introduce the **Block Bootstrap method** for preparing the Discriminator's training data, ensuring approximate independent and identically distributed (i.i.d.) samples while preserving the time series' correlation structure.

## Motivation

Traditional adversarial estimators face difficulties when applied directly to time series data due to their implicit assumption of independent data points. The creators of the Adversarial Estimator themselves highlighted this as an open area of research, emphasizing the need for a Discriminator capable of incorporating serial correlation.

This project is motivated by:
* The promising asymptotic properties (consistency and efficiency) and competitive finite sample performance of the Adversarial Estimator.
* The necessity to explicitly account for temporal dependencies in time series data to achieve accurate and stable parameter estimations.
* Leveraging the capabilities of Neural Networks, particularly RNNs like LSTMs, which are designed to process sequential data and manage long-term dependencies.

## Key Contributions

* **LSTM-based Discriminator:** Proposed and implemented an LSTM network as the Discriminator to effectively capture the intertemporal dependencies in time series data, a crucial adaptation for the adversarial framework.
* **Block Bootstrap Integration:** Employed the Block Bootstrap method to generate approximately i.i.d. training samples for the Discriminator, overcoming stability and convergence issues encountered with naive sampling of correlated time series.
* **Preliminary Simulation Results:** Provided qualitative simulation results for MA(1), AR(1), and AR(2) models, demonstrating promising convergence behavior where estimated parameters oscillate around their true values.

## Methodology Overview

The project follows the adversarial estimation procedure, adapted for time series:

1.  **Generator (G):** Represents the parametric time series model that simulates "fake" data based on its current parameter estimates.
2.  **Discriminator (D):** An LSTM Neural Network trained to distinguish between "real" data (from the true underlying process) and "fake" data (generated by G).
3.  **Block Bootstrap:** Before training the Discriminator in each step, "real" time series samples are created by resampling blocks from a long master time series. This ensures the Discriminator is trained on samples that preserve internal correlations but are approximately independent from each other.
4.  **Iterative Training:** The Discriminator and Generator are trained competitively. The Discriminator learns to identify real vs. fake, while the Generator updates its parameters to produce data that increasingly "fools" the Discriminator.
5.  **Parameter Convergence:** The process continues until the Generator's parameters stabilize, indicating that the simulated data is indistinguishable from the real data, thereby yielding the estimated parameters.

## Simulation Results and Findings

Preliminary simulations were conducted for:
* **MA(1) Model:** Estimated $\hat{\phi}=0.7317$ (True $\phi=0.7$) and $\hat{\sigma}=1.024$ (True $\sigma=1$).
* **AR(1) Model:** Estimated $\hat{\theta}=0.4613$ (True $\theta=0.4$) and $\hat{\sigma}=1.0229$ (True $\sigma=1$).
* **AR(2) Model:** Estimated $\hat{\theta_1}=0.4512$ (True $\theta_1=0.4$), $\hat{\theta_2}=-0.1889$ (True $\theta_2=-0.2$), and $\hat{\sigma}=1.0127$ (True $\sigma=1$).

The key findings are:
* The LSTM-based Discriminator captures the data correlation needed for a proper adaptation.
* The transformation of the training dataset using Block Bootstrap is crucial for stability and proper performance of the algorithm.
* Despite being computationally demanding, the simulations show promising convergence behavior compared to initial attempts where estimated parameters oscillate around their true values. These results suggest that the adapted framework is a viable direction for future research.

## Repository Contents

* `TFM.pdf`: The complete Master's Thesis document, providing a comprehensive overview of the project.
* `TFM_defense.pdf`: Slides complementing the core Document.
* `LSTM_for_Adversarial_Estimator.ipynb`: A Colab Notebook containing the Python code for implementing the adversarial estimator with the LSTM Discriminator and Block Bootstrap. This notebook includes the simulation setups and visualization code for MA(1), AR(1), and AR(2) models.

